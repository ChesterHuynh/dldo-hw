{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import time\\n\\nimport numpy as np\\nimport torch\\nimport torch.nn as nn\\nfrom sklearn.model_selection import train_test_split\";\n",
       "                var nbb_formatted_code = \"import time\\n\\nimport numpy as np\\nimport torch\\nimport torch.nn as nn\\nfrom sklearn.model_selection import train_test_split\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11c0d06d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"torch.manual_seed(0)\";\n",
       "                var nbb_formatted_code = \"torch.manual_seed(0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the neural network\n",
    "\n",
    "Create a class for network structure.\n",
    "\n",
    "Create helper functions to initialize the weights and to evaluate the training and testing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class My_Net(nn.Module):\\n    def __init__(self, n_features, n_classes, hidden_dim1=15, hidden_dim2=15):\\n\\n        super(My_Net, self).__init__()\\n\\n        self.layer_1 = nn.Linear(n_features, hidden_dim1)\\n        self.layer_2 = nn.Linear(hidden_dim1, hidden_dim2)\\n        self.layer_3 = nn.Linear(hidden_dim2, n_classes)\\n\\n        self.relu = nn.ReLU()\\n        self.softmax = nn.Softmax(dim=1)\\n\\n    def forward(self, input_data):\\n        out = self.layer_1(input_data)\\n        out = self.relu(out)\\n        out = self.layer_2(out)\\n        out = self.relu(out)\\n        out = self.layer_3(out)\\n        out = self.softmax(out)\\n        return out\";\n",
       "                var nbb_formatted_code = \"class My_Net(nn.Module):\\n    def __init__(self, n_features, n_classes, hidden_dim1=15, hidden_dim2=15):\\n\\n        super(My_Net, self).__init__()\\n\\n        self.layer_1 = nn.Linear(n_features, hidden_dim1)\\n        self.layer_2 = nn.Linear(hidden_dim1, hidden_dim2)\\n        self.layer_3 = nn.Linear(hidden_dim2, n_classes)\\n\\n        self.relu = nn.ReLU()\\n        self.softmax = nn.Softmax(dim=1)\\n\\n    def forward(self, input_data):\\n        out = self.layer_1(input_data)\\n        out = self.relu(out)\\n        out = self.layer_2(out)\\n        out = self.relu(out)\\n        out = self.layer_3(out)\\n        out = self.softmax(out)\\n        return out\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class My_Net(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, hidden_dim1=15, hidden_dim2=15):\n",
    "\n",
    "        super(My_Net, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(n_features, hidden_dim1)\n",
    "        self.layer_2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.layer_3 = nn.Linear(hidden_dim2, n_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        out = self.layer_1(input_data)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def weights_init(m):\\n    \\\"\\\"\\\"Initialize the network using Xavier initialization.\\\"\\\"\\\"\\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\\n        nn.init.xavier_uniform_(m.weight.data)\";\n",
       "                var nbb_formatted_code = \"def weights_init(m):\\n    \\\"\\\"\\\"Initialize the network using Xavier initialization.\\\"\\\"\\\"\\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\\n        nn.init.xavier_uniform_(m.weight.data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"Initialize the network using Xavier initialization.\"\"\"\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def train_eval(net, train_loader, loss, verbose=True):\\n\\n    correct = 0\\n    total = 0\\n    loss_sum = 0\\n    num_batches = 0\\n    for inputs, labels in train_loader:\\n        outputs = net(inputs)\\n        predicted = torch.argmax(outputs, dim=1)\\n        total += labels.size(0)\\n        correct += (predicted.int() == labels.int()).sum()\\n        loss_sum += loss(outputs, labels).item()\\n        num_batches += 1\\n\\n    if verbose:\\n        print(f\\\"Train accuracy: {100 * correct.item() / total:.3f}%\\\")\\n\\n    return loss_sum / num_batches, correct.item() / total\";\n",
       "                var nbb_formatted_code = \"def train_eval(net, train_loader, loss, verbose=True):\\n\\n    correct = 0\\n    total = 0\\n    loss_sum = 0\\n    num_batches = 0\\n    for inputs, labels in train_loader:\\n        outputs = net(inputs)\\n        predicted = torch.argmax(outputs, dim=1)\\n        total += labels.size(0)\\n        correct += (predicted.int() == labels.int()).sum()\\n        loss_sum += loss(outputs, labels).item()\\n        num_batches += 1\\n\\n    if verbose:\\n        print(f\\\"Train accuracy: {100 * correct.item() / total:.3f}%\\\")\\n\\n    return loss_sum / num_batches, correct.item() / total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_eval(net, train_loader, loss, verbose=True):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0\n",
    "    num_batches = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = net(inputs)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.int() == labels.int()).sum()\n",
    "        loss_sum += loss(outputs, labels).item()\n",
    "        num_batches += 1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Train accuracy: {100 * correct.item() / total:.3f}%\")\n",
    "\n",
    "    return loss_sum / num_batches, correct.item() / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def test_eval(net, test_loader, loss, verbose=True):\\n\\n    correct = 0\\n    total = 0\\n    loss_sum = 0\\n    num_batches = 0\\n    for inputs, labels in test_loader:\\n        outputs = net(inputs)\\n        predicted = torch.argmax(outputs, dim=1)\\n        total += labels.size(0)\\n        correct += (predicted.int() == labels.int()).sum()\\n        loss_sum += loss(outputs, labels).item()\\n        num_batches += 1\\n\\n    if verbose:\\n        print(f\\\"Test accuracy: {100 * correct.item() / total:.3f}%\\\")\\n\\n    return loss_sum / num_batches, correct.item() / total\";\n",
       "                var nbb_formatted_code = \"def test_eval(net, test_loader, loss, verbose=True):\\n\\n    correct = 0\\n    total = 0\\n    loss_sum = 0\\n    num_batches = 0\\n    for inputs, labels in test_loader:\\n        outputs = net(inputs)\\n        predicted = torch.argmax(outputs, dim=1)\\n        total += labels.size(0)\\n        correct += (predicted.int() == labels.int()).sum()\\n        loss_sum += loss(outputs, labels).item()\\n        num_batches += 1\\n\\n    if verbose:\\n        print(f\\\"Test accuracy: {100 * correct.item() / total:.3f}%\\\")\\n\\n    return loss_sum / num_batches, correct.item() / total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_eval(net, test_loader, loss, verbose=True):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0\n",
    "    num_batches = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = net(inputs)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.int() == labels.int()).sum()\n",
    "        loss_sum += loss(outputs, labels).item()\n",
    "        num_batches += 1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Test accuracy: {100 * correct.item() / total:.3f}%\")\n",
    "\n",
    "    return loss_sum / num_batches, correct.item() / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def main(\\n    train_loader, test_loader, n_features, n_classes, epochs=25, lr=1e-2\\n):\\n\\n    # Initialize the neural network\\n    net = My_Net(n_features, n_classes)\\n    loss = nn.CrossEntropyLoss()\\n    opt = torch.optim.Adam(net.parameters(), lr=lr)\\n    net.apply(weights_init)\\n\\n    train_loss_store = []\\n    train_acc_store = []\\n    test_loss_store = []\\n    test_acc_store = []\\n\\n    for epoch in range(epochs):\\n        time1 = time.time()\\n        print(f\\\"Epoch {epoch + 1}:\\\")\\n        for i, (feat, label) in enumerate(train_loader, 0):\\n            opt.zero_grad()\\n            outputs = net(feat)\\n            l = loss(outputs, label)\\n            l.backward()\\n            opt.step()\\n\\n        l_temp, acc_temp = train_eval(net, train_loader, loss)\\n        train_loss_store.append(l_temp)\\n        train_acc_store.append(acc_temp)\\n\\n        l_temp, acc_temp = test_eval(net, test_loader, loss)\\n        test_loss_store.append(l_temp)\\n        test_acc_store.append(acc_temp)\\n\\n        time2 = time.time()\\n        print(f\\\"Time lapse: {time2-time1:.2f} sec \\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def main(train_loader, test_loader, n_features, n_classes, epochs=25, lr=1e-2):\\n\\n    # Initialize the neural network\\n    net = My_Net(n_features, n_classes)\\n    loss = nn.CrossEntropyLoss()\\n    opt = torch.optim.Adam(net.parameters(), lr=lr)\\n    net.apply(weights_init)\\n\\n    train_loss_store = []\\n    train_acc_store = []\\n    test_loss_store = []\\n    test_acc_store = []\\n\\n    for epoch in range(epochs):\\n        time1 = time.time()\\n        print(f\\\"Epoch {epoch + 1}:\\\")\\n        for i, (feat, label) in enumerate(train_loader, 0):\\n            opt.zero_grad()\\n            outputs = net(feat)\\n            l = loss(outputs, label)\\n            l.backward()\\n            opt.step()\\n\\n        l_temp, acc_temp = train_eval(net, train_loader, loss)\\n        train_loss_store.append(l_temp)\\n        train_acc_store.append(acc_temp)\\n\\n        l_temp, acc_temp = test_eval(net, test_loader, loss)\\n        test_loss_store.append(l_temp)\\n        test_acc_store.append(acc_temp)\\n\\n        time2 = time.time()\\n        print(f\\\"Time lapse: {time2-time1:.2f} sec \\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main(train_loader, test_loader, n_features, n_classes, epochs=25, lr=1e-2):\n",
    "\n",
    "    # Initialize the neural network\n",
    "    net = My_Net(n_features, n_classes)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    net.apply(weights_init)\n",
    "\n",
    "    train_loss_store = []\n",
    "    train_acc_store = []\n",
    "    test_loss_store = []\n",
    "    test_acc_store = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        time1 = time.time()\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        for i, (feat, label) in enumerate(train_loader, 0):\n",
    "            opt.zero_grad()\n",
    "            outputs = net(feat)\n",
    "            l = loss(outputs, label)\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "\n",
    "        l_temp, acc_temp = train_eval(net, train_loader, loss)\n",
    "        train_loss_store.append(l_temp)\n",
    "        train_acc_store.append(acc_temp)\n",
    "\n",
    "        l_temp, acc_temp = test_eval(net, test_loader, loss)\n",
    "        test_loss_store.append(l_temp)\n",
    "        test_acc_store.append(acc_temp)\n",
    "\n",
    "        time2 = time.time()\n",
    "        print(f\"Time lapse: {time2-time1:.2f} sec \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a helper function to parse the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def parse_data(fpath):\\n\\n    # Input the data and split into features and labels\\n    data = np.genfromtxt(fpath, dtype=np.int64, skip_header=7)\\n    X, y = data[:, :-1], data[:, -1]\\n    n_classes = len(np.unique(y))\\n    n_features = X.shape[1]\\n\\n    # Index classes starting at 0 for CrossEntropyLoss() to work\\n    y -= 1\\n\\n    # Split into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\n\\n    # Convert to tensors\\n    X_train = torch.Tensor(X_train)\\n    X_test = torch.Tensor(X_test)\\n    y_train = torch.LongTensor(y_train)\\n    y_test = torch.LongTensor(y_test)\\n\\n    # Pick optimal batch size\\n    if \\\"stable4\\\" in fpath:\\n        batch_size = 1\\n    elif \\\"stable5\\\" in fpath:\\n        batch_size = 32\\n    elif \\\"stable6\\\" in fpath:\\n        batch_size = 64\\n\\n    # Make data loaders for the test and training set\\n    train = torch.utils.data.TensorDataset(X_train, y_train)\\n    test = torch.utils.data.TensorDataset(X_test, y_test)\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        train, batch_size=batch_size, num_workers=2\\n    )\\n    test_loader = torch.utils.data.DataLoader(\\n        test, batch_size=batch_size, shuffle=False, num_workers=2\\n    )\\n\\n    return train_loader, test_loader, n_features, n_classes\";\n",
       "                var nbb_formatted_code = \"def parse_data(fpath):\\n\\n    # Input the data and split into features and labels\\n    data = np.genfromtxt(fpath, dtype=np.int64, skip_header=7)\\n    X, y = data[:, :-1], data[:, -1]\\n    n_classes = len(np.unique(y))\\n    n_features = X.shape[1]\\n\\n    # Index classes starting at 0 for CrossEntropyLoss() to work\\n    y -= 1\\n\\n    # Split into training and testing sets\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\\n\\n    # Convert to tensors\\n    X_train = torch.Tensor(X_train)\\n    X_test = torch.Tensor(X_test)\\n    y_train = torch.LongTensor(y_train)\\n    y_test = torch.LongTensor(y_test)\\n\\n    # Pick optimal batch size\\n    if \\\"stable4\\\" in fpath:\\n        batch_size = 1\\n    elif \\\"stable5\\\" in fpath:\\n        batch_size = 32\\n    elif \\\"stable6\\\" in fpath:\\n        batch_size = 64\\n\\n    # Make data loaders for the test and training set\\n    train = torch.utils.data.TensorDataset(X_train, y_train)\\n    test = torch.utils.data.TensorDataset(X_test, y_test)\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        train, batch_size=batch_size, num_workers=2\\n    )\\n    test_loader = torch.utils.data.DataLoader(\\n        test, batch_size=batch_size, shuffle=False, num_workers=2\\n    )\\n\\n    return train_loader, test_loader, n_features, n_classes\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_data(fpath):\n",
    "\n",
    "    # Input the data and split into features and labels\n",
    "    data = np.genfromtxt(fpath, dtype=np.int64, skip_header=7)\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    n_classes = len(np.unique(y))\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # Index classes starting at 0 for CrossEntropyLoss() to work\n",
    "    y -= 1\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "\n",
    "    # Pick optimal batch size\n",
    "    if \"stable4\" in fpath:\n",
    "        batch_size = 1\n",
    "    elif \"stable5\" in fpath:\n",
    "        batch_size = 32\n",
    "    elif \"stable6\" in fpath:\n",
    "        batch_size = 64\n",
    "\n",
    "    # Make data loaders for the test and training set\n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, num_workers=2\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader, n_features, n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train accuracy: 63.636%\n",
      "Test accuracy: 60.000%\n",
      "Time lapse: 0.23 sec \n",
      "\n",
      "Epoch 2:\n",
      "Train accuracy: 63.636%\n",
      "Test accuracy: 60.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 3:\n",
      "Train accuracy: 75.000%\n",
      "Test accuracy: 60.000%\n",
      "Time lapse: 0.18 sec \n",
      "\n",
      "Epoch 4:\n",
      "Train accuracy: 79.545%\n",
      "Test accuracy: 60.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 5:\n",
      "Train accuracy: 79.545%\n",
      "Test accuracy: 60.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 6:\n",
      "Train accuracy: 81.818%\n",
      "Test accuracy: 60.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n",
      "Epoch 7:\n",
      "Train accuracy: 88.636%\n",
      "Test accuracy: 70.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n",
      "Epoch 8:\n",
      "Train accuracy: 93.182%\n",
      "Test accuracy: 70.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n",
      "Epoch 9:\n",
      "Train accuracy: 93.182%\n",
      "Test accuracy: 75.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 10:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 11:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 12:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 13:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 14:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 15:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 16:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 17:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n",
      "Epoch 18:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 75.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 19:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 20:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.16 sec \n",
      "\n",
      "Epoch 21:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n",
      "Epoch 22:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n",
      "Epoch 23:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.19 sec \n",
      "\n",
      "Epoch 24:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.20 sec \n",
      "\n",
      "Epoch 25:\n",
      "Train accuracy: 95.455%\n",
      "Test accuracy: 80.000%\n",
      "Time lapse: 0.17 sec \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"fpath = \\\"stable4.txt\\\"\\ntrain_loader, test_loader, n_features, n_classes = parse_data(fpath)\\nmain(train_loader, test_loader, n_features, n_classes)\";\n",
       "                var nbb_formatted_code = \"fpath = \\\"stable4.txt\\\"\\ntrain_loader, test_loader, n_features, n_classes = parse_data(fpath)\\nmain(train_loader, test_loader, n_features, n_classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpath = \"stable4.txt\"\n",
    "train_loader, test_loader, n_features, n_classes = parse_data(fpath)\n",
    "main(train_loader, test_loader, n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train accuracy: 55.028%\n",
      "Test accuracy: 57.143%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 2:\n",
      "Train accuracy: 68.017%\n",
      "Test accuracy: 63.312%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 3:\n",
      "Train accuracy: 76.955%\n",
      "Test accuracy: 68.831%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 4:\n",
      "Train accuracy: 78.911%\n",
      "Test accuracy: 72.403%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 5:\n",
      "Train accuracy: 81.006%\n",
      "Test accuracy: 72.078%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 6:\n",
      "Train accuracy: 82.263%\n",
      "Test accuracy: 74.026%\n",
      "Time lapse: 0.13 sec \n",
      "\n",
      "Epoch 7:\n",
      "Train accuracy: 81.844%\n",
      "Test accuracy: 73.701%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 8:\n",
      "Train accuracy: 82.402%\n",
      "Test accuracy: 74.351%\n",
      "Time lapse: 0.13 sec \n",
      "\n",
      "Epoch 9:\n",
      "Train accuracy: 83.380%\n",
      "Test accuracy: 75.649%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 10:\n",
      "Train accuracy: 83.240%\n",
      "Test accuracy: 76.623%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 11:\n",
      "Train accuracy: 83.520%\n",
      "Test accuracy: 75.325%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 12:\n",
      "Train accuracy: 83.659%\n",
      "Test accuracy: 76.299%\n",
      "Time lapse: 0.15 sec \n",
      "\n",
      "Epoch 13:\n",
      "Train accuracy: 84.916%\n",
      "Test accuracy: 76.299%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 14:\n",
      "Train accuracy: 85.475%\n",
      "Test accuracy: 77.597%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 15:\n",
      "Train accuracy: 85.615%\n",
      "Test accuracy: 77.597%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 16:\n",
      "Train accuracy: 85.754%\n",
      "Test accuracy: 77.273%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 17:\n",
      "Train accuracy: 86.173%\n",
      "Test accuracy: 78.247%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 18:\n",
      "Train accuracy: 86.313%\n",
      "Test accuracy: 79.545%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 19:\n",
      "Train accuracy: 87.151%\n",
      "Test accuracy: 79.545%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 20:\n",
      "Train accuracy: 87.151%\n",
      "Test accuracy: 79.545%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 21:\n",
      "Train accuracy: 87.291%\n",
      "Test accuracy: 79.870%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 22:\n",
      "Train accuracy: 86.034%\n",
      "Test accuracy: 77.922%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 23:\n",
      "Train accuracy: 87.011%\n",
      "Test accuracy: 78.247%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 24:\n",
      "Train accuracy: 87.989%\n",
      "Test accuracy: 77.597%\n",
      "Time lapse: 0.14 sec \n",
      "\n",
      "Epoch 25:\n",
      "Train accuracy: 86.872%\n",
      "Test accuracy: 78.896%\n",
      "Time lapse: 0.14 sec \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"fpath = \\\"stable5.txt\\\"\\ntrain_loader, test_loader, n_features, n_classes = parse_data(fpath)\\nmain(train_loader, test_loader, n_features, n_classes)\";\n",
       "                var nbb_formatted_code = \"fpath = \\\"stable5.txt\\\"\\ntrain_loader, test_loader, n_features, n_classes = parse_data(fpath)\\nmain(train_loader, test_loader, n_features, n_classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpath = \"stable5.txt\"\n",
    "train_loader, test_loader, n_features, n_classes = parse_data(fpath)\n",
    "main(train_loader, test_loader, n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train accuracy: 66.844%\n",
      "Test accuracy: 66.168%\n",
      "Time lapse: 0.72 sec \n",
      "\n",
      "Epoch 2:\n",
      "Train accuracy: 66.844%\n",
      "Test accuracy: 66.168%\n",
      "Time lapse: 0.78 sec \n",
      "\n",
      "Epoch 3:\n",
      "Train accuracy: 66.844%\n",
      "Test accuracy: 66.168%\n",
      "Time lapse: 0.78 sec \n",
      "\n",
      "Epoch 4:\n",
      "Train accuracy: 70.781%\n",
      "Test accuracy: 70.766%\n",
      "Time lapse: 0.75 sec \n",
      "\n",
      "Epoch 5:\n",
      "Train accuracy: 71.683%\n",
      "Test accuracy: 71.580%\n",
      "Time lapse: 0.72 sec \n",
      "\n",
      "Epoch 6:\n",
      "Train accuracy: 72.769%\n",
      "Test accuracy: 72.424%\n",
      "Time lapse: 0.72 sec \n",
      "\n",
      "Epoch 7:\n",
      "Train accuracy: 73.706%\n",
      "Test accuracy: 73.146%\n",
      "Time lapse: 0.73 sec \n",
      "\n",
      "Epoch 8:\n",
      "Train accuracy: 73.863%\n",
      "Test accuracy: 73.512%\n",
      "Time lapse: 0.84 sec \n",
      "\n",
      "Epoch 9:\n",
      "Train accuracy: 73.955%\n",
      "Test accuracy: 73.645%\n",
      "Time lapse: 0.72 sec \n",
      "\n",
      "Epoch 10:\n",
      "Train accuracy: 73.567%\n",
      "Test accuracy: 73.136%\n",
      "Time lapse: 0.72 sec \n",
      "\n",
      "Epoch 11:\n",
      "Train accuracy: 74.631%\n",
      "Test accuracy: 73.848%\n",
      "Time lapse: 0.71 sec \n",
      "\n",
      "Epoch 12:\n",
      "Train accuracy: 74.548%\n",
      "Test accuracy: 73.736%\n",
      "Time lapse: 0.70 sec \n",
      "\n",
      "Epoch 13:\n",
      "Train accuracy: 75.372%\n",
      "Test accuracy: 74.733%\n",
      "Time lapse: 0.71 sec \n",
      "\n",
      "Epoch 14:\n",
      "Train accuracy: 74.587%\n",
      "Test accuracy: 74.275%\n",
      "Time lapse: 0.74 sec \n",
      "\n",
      "Epoch 15:\n",
      "Train accuracy: 75.603%\n",
      "Test accuracy: 74.875%\n",
      "Time lapse: 0.74 sec \n",
      "\n",
      "Epoch 16:\n",
      "Train accuracy: 76.052%\n",
      "Test accuracy: 75.333%\n",
      "Time lapse: 0.74 sec \n",
      "\n",
      "Epoch 17:\n",
      "Train accuracy: 75.572%\n",
      "Test accuracy: 75.069%\n",
      "Time lapse: 0.73 sec \n",
      "\n",
      "Epoch 18:\n",
      "Train accuracy: 76.034%\n",
      "Test accuracy: 75.353%\n",
      "Time lapse: 0.72 sec \n",
      "\n",
      "Epoch 19:\n",
      "Train accuracy: 76.300%\n",
      "Test accuracy: 75.547%\n",
      "Time lapse: 0.73 sec \n",
      "\n",
      "Epoch 20:\n",
      "Train accuracy: 75.829%\n",
      "Test accuracy: 75.353%\n",
      "Time lapse: 0.74 sec \n",
      "\n",
      "Epoch 21:\n",
      "Train accuracy: 76.222%\n",
      "Test accuracy: 75.201%\n",
      "Time lapse: 0.76 sec \n",
      "\n",
      "Epoch 22:\n",
      "Train accuracy: 76.178%\n",
      "Test accuracy: 75.211%\n",
      "Time lapse: 0.79 sec \n",
      "\n",
      "Epoch 23:\n",
      "Train accuracy: 76.021%\n",
      "Test accuracy: 75.282%\n",
      "Time lapse: 0.76 sec \n",
      "\n",
      "Epoch 24:\n",
      "Train accuracy: 76.156%\n",
      "Test accuracy: 75.262%\n",
      "Time lapse: 0.80 sec \n",
      "\n",
      "Epoch 25:\n",
      "Train accuracy: 76.322%\n",
      "Test accuracy: 75.557%\n",
      "Time lapse: 0.79 sec \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"fpath = \\\"stable6.txt\\\"\\ntrain_loader, test_loader, n_features, n_classes = parse_data(fpath)\\nmain(train_loader, test_loader, n_features, n_classes)\";\n",
       "                var nbb_formatted_code = \"fpath = \\\"stable6.txt\\\"\\ntrain_loader, test_loader, n_features, n_classes = parse_data(fpath)\\nmain(train_loader, test_loader, n_features, n_classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpath = \"stable6.txt\"\n",
    "train_loader, test_loader, n_features, n_classes = parse_data(fpath)\n",
    "main(train_loader, test_loader, n_features, n_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dldo': conda)",
   "language": "python",
   "name": "python37664bitdldocondab3c479e81e2546cd9d29f3c283b7bc86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
